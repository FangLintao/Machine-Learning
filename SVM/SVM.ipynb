{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Theory behind Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "class support_vector_machine:\n",
    "    def __init__(self,visulization = True):\n",
    "        self.visulization = visulization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visulization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            \n",
    "    def fit(self,data):\n",
    "        \"\"\"\n",
    "        train\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        # { ||w|| : [w,b] }\n",
    "        opt_dict = {}\n",
    "        transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "        all_data = []\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        step_sizes =[self.max_feature_value * 0.1,\n",
    "                     self.max_feature_value * 0.01,\n",
    "                     self.max_feature_value * 0.001]\n",
    "        b_range_multiple = 5\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple), \n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi = i\n",
    "                                if not yi*(np.dot(w_t,xi)+b)>=1:\n",
    "                                    found_option = False\n",
    "                                    #break\n",
    "                        if found_option:\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "                if w[0]<0:\n",
    "                    optimized = True\n",
    "                    print(\"optimized a step.\")\n",
    "                else:\n",
    "                    w = w - step\n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #print(\"norms : {}\".format(norms))\n",
    "            # ||w|| :[w,b]\n",
    "            opt_choice =opt_dict[norms[0]]\n",
    "            #print(\"opt_choice : {}\".format(opt_choice))\n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optimum = opt_choice[0][0] + step*2\n",
    "        for i in self.data:\n",
    "            for xi in self.data[i]:\n",
    "                yi = i\n",
    "                print(xi,\":\", yi*(np.dot(self.w,xi)+self.b))\n",
    "    def predict(self,features):\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification !=0 and self.visulization:\n",
    "            self.ax.scatter(features[0],features[1],s=200, marker='*',c = self.colors[classification])\n",
    "        return classification\n",
    "    def visualize(self):\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color = self.colors[i]) for x in data_dict[i]]for i in data_dict]\n",
    "        def hyperplane(x,w,b,v):\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "        datarange = (self.min_feature_value*0.9, self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        psv1 = hyperplane(hyp_x_min,self.w,self.b,1)\n",
    "        psv2 = hyperplane(hyp_x_max,self.w,self.b,1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2],'k')\n",
    "        \n",
    "        nsv1 = hyperplane(hyp_x_min,self.w,self.b,-1)\n",
    "        nsv2 = hyperplane(hyp_x_max,self.w,self.b,-1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2],'k')\n",
    "        \n",
    "        db1 = hyperplane(hyp_x_min,self.w,self.b,0)\n",
    "        db2 = hyperplane(hyp_x_max,self.w,self.b,0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2],'y--')\n",
    "        plt.show()\n",
    "\n",
    "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),1:np.array([[5,1],[6,-1],[7,3]])}\n",
    "svm = support_vector_machine()\n",
    "svm.fit(data = data_dict)\n",
    "predict = [[0,10],[1,3],[3,4],[3,5],[5,5],[5,6],[6,-5],[5,8]]\n",
    "for p in predict:\n",
    "    svm.predict(p)\n",
    "svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=50, centers=2,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1, 3.5)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)\n",
    "\n",
    "for m, b in [(1, 0.65), (0.5, 1.6), (-0.2, 2.9)]:\n",
    "    plt.plot(xfit, m * xfit + b, '-k')\n",
    "\n",
    "plt.xlim(-1, 3.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines: Maximizing the Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1, 3.5)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "\n",
    "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]:\n",
    "    yfit = m * xfit + b\n",
    "    plt.plot(xfit, yfit, '-k')\n",
    "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
    "                     color='#AAAAAA', alpha=0.4)\n",
    "\n",
    "plt.xlim(-1, 3.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting a support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    \n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm(N=10, ax=None):\n",
    "    X, y = make_blobs(n_samples=200, centers=2,\n",
    "                      random_state=0, cluster_std=0.60)\n",
    "    X = X[:N]\n",
    "    y = y[:N]\n",
    "    model = SVC(kernel='linear', C=1E10)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    ax = ax or plt.gca()\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "    ax.set_xlim(-1, 4)\n",
    "    ax.set_ylim(-1, 6)\n",
    "    plot_svc_decision_function(model, ax)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "for axi, N in zip(ax, [60, 120]):\n",
    "    plot_svm(N, axi)\n",
    "    axi.set_title('N = {0}'.format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "interact(plot_svm, N=[10, 200], ax=fixed(None));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beyond linear boundaries: Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_circles\n",
    "X, y = make_circles(100, factor=.1, noise=.1)\n",
    "\n",
    "clf = SVC(kernel='linear').fit(X, y)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.exp(-(X ** 2).sum(1))\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('r')\n",
    "\n",
    "interact(plot_3D, elev=[-90, 90], azip=(-180, 180),\n",
    "         X=fixed(X), y=fixed(y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', C=1E6)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf)\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
    "            s=300, lw=1, facecolors='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning the SVM: Softening Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  random_state=0, cluster_std=1.2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  random_state=0, cluster_std=0.8)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "for axi, C in zip(ax, [10.0, 0.1]):\n",
    "    model = SVC(kernel='linear', C=C).fit(X, y)\n",
    "    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "    plot_svc_decision_function(model, axi)\n",
    "    axi.scatter(model.support_vectors_[:, 0],\n",
    "                model.support_vectors_[:, 1],\n",
    "                s=300, lw=1, facecolors='none');\n",
    "    axi.set_title('C = {0:.1f}'.format(C), size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
